{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Distance and similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance metrics\n",
    "\n",
    "The distance metric represents the distance between two points $x$ and $y$.\n",
    "When $x$ is a point in a $n$-dimensional space then $x$ can be represented by a vector of length $n$. \n",
    "\n",
    "\n",
    "### Applications\n",
    "Some examples of applications of distance metrics:\n",
    "- k-nearest neighbors algorithm: to calculate the k labelled points that are most near to the new unlabelled point.\n",
    "- Clustering algorithms: to calculate the distance between records inside the cluster and to calculate the distance between different clusters. For example, k-means clustering.\n",
    "\n",
    "\n",
    "Some frequently used distance metrics include:\n",
    "- Euclidean distance: $$D_{euc}(x, y) = \\left(\\sum_{i=1}^{n}(x_{i}-y_{i})^2\\right)^{0.5}$$\n",
    "- Manhattan distance: $$D_{manh}(x, y) = \\sum_{i=1}^{n} abs(x_{i}-y_{i})$$\n",
    "\n",
    "In general, distance metrics satisfy some properties such as:\n",
    "- The distance between two points is non-negative. \n",
    "- The distance from a point to the point itself is equal to 0. \n",
    "- The distance from point $i$ to point $j$ is exactly equal to the distance from point $j$ to point $i$ (symmetry). \n",
    "- The distance from point $i$ to point $j$ via point $k$ is always longer than the direct distance from $i$ to $j$ (triangle inequality). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance:  2\n"
     ]
    }
   ],
   "source": [
    "# function to calculate manhattan distance between two points x and y\n",
    "def manhattan_distance(x, y):\n",
    "    return sum(abs(x-y))\n",
    "        \n",
    "x = numpy.array([1,3])\n",
    "y = numpy.array([2,4])\n",
    "print(\"Manhattan distance: \", manhattan_distance(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1\n",
    "\n",
    "Create a function to calculate the Euclidean distance between two points x and y. \n",
    "Make sure that you do not use loops!\n",
    "\n",
    "For example:\n",
    "```python\n",
    "a = numpy.array([0.0, 0.0])\n",
    "b = numpy.array([1.0, 1.0])\n",
    "print(euclidean(a, b))\n",
    "```\n",
    "Output:\n",
    "```\n",
    "1.41421356237\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Exercise 6.2\n",
    "\n",
    "Load the iris data into a 150x4 numpy array. Compute the Euclidean distance between the first row and each other row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity metrics\n",
    "\n",
    "A similarity metric quantifies how similar two objects are. \n",
    "\n",
    "One often used similarity metric in data science is the cosine similarity.\n",
    "When the similarity metric is equal to 1 the vectors point in the same direction, and when the similarity metric is equal to -1 then the vectors are the opposite of each other.\n",
    "\n",
    "Cosine similarity: $$cosine(x, y) = \\frac{x^Ty}{||x||\\cdot ||y||} = \\frac{\\sum_{i=1}^n x_i y_i}{\\left(\\sum_{i=1}^n x_{i}^2\\right)^{0.5} \\left(\\sum_{i=1}^n y_{i}^2\\right)^{0.5}}$$\n",
    "\n",
    "The cosine similarity between $x$ and $y$ is the dot product between $x$ and $y$ divided by the product of the L2-norms of $x$ and $y$.\n",
    "\n",
    "In text-mining the cosine similarity can be used to represent the similarity between two documents.\n",
    "For each document a vector with the word frequencies is made. \n",
    "\n",
    "The cosine similarity between those vectors is calculated and this means that when the documents contain a lot of the same words the documents are said to be more similar than documents with hardly any overlapping words.\n",
    "\n",
    "A common similarity metrics for comparing categorical data is:\n",
    "- Jaquard's coefficient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Create a function that calculates the cosine similarity between two vectors. Do not use for-loops.\n",
    "\n",
    "For example:\n",
    "```python\n",
    "a = numpy.array([0.0, 1.0])\n",
    "b = numpy.array([1.0, 0.0])\n",
    "c = numpy.array([0.0, -1.0])\n",
    "print(cosine(a, b))\n",
    "print(cosine(a, a))\n",
    "print(cosine(a, c))\n",
    "```\n",
    "Output:\n",
    "```\n",
    "0.0\n",
    "1.0\n",
    "-1.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance measures for comparing strings\n",
    "\n",
    "Distance measures for comparing strings with each other:\n",
    "- Hamming distance: number of positions at which two strings of the same length differ.\n",
    "    $$D_{hamming}(x, y) =  \\sum_{i=1}^{n} x_{i} \\neq y_{i} $$\n",
    "- Levenshtein distance: the minimum number of operations required to transform one string into another string. The operations are insertion, deletion and substitutions and each operations has a cost (often unit costs are used). The Levenshtein distance can be used in a lot of text mining techniques where the similarity between two words needs to be measured. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.3\n",
    "Create your own function to calculate the Hamming distance between two strings. The strings need to have the same length.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "a = 'Panama'\n",
    "b = 'Pamela'\n",
    "hamming(a, b)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance metrics in scikit-learn\n",
    "\n",
    "There is no need to create your own code/function to calculate the distances.\n",
    "In the library `scikit-learn` the class `DistanceMetric` will calculate the distances for you.\n",
    "\n",
    "Scikit-learn is a library for machine learning algorithms in Python. Scikit-learn includes functions for classification, regression, clustering, dimensionality reduction, model selection and preprocessing. \n",
    "For more information:  http://scikit-learn.org/stable/\n",
    "\n",
    "The class to calculate distances is in the module \"neighbors\" of the scikit-learn library.\n",
    "One can access the class via: `sklearn.neighbors.DistanceMetric`\n",
    "Note that you first have to import the library `sklearn` and more specifically you have to import `sklearn.neighbors`.\n",
    "\n",
    "The `DistanceMetric` class includes different distance metrics, such as Euclidean and Manhattan. Also other distance metrics are present, such as chebyshev, minkowski, mahalanobis, haversine, hamming, canberra, braycurtis and many more. \n",
    "\n",
    "For more information about the distance metrics that are included in the `DistanceMetric` class:  http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\n",
    "\n",
    "The most important methods of the `DistanceMetric` class are the `get_metric()` and the `pairwise()` functions. \n",
    "The `get_metric` function is used to specify which metric is used, for example 'euclidean' or 'manhattan'. \n",
    "The `pairwise` function is used to calculate the pairwise distances between points in an array x. \n",
    "See the examples below.\n",
    "\n",
    "There is also a simple function to calculate pairwise distances according to a number of metrics:\n",
    "```python\n",
    "from sklearn.metrics.pairwise import pairwise_distances```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance:\n",
      "[[ 0.          1.41421356  3.        ]\n",
      " [ 1.41421356  0.          2.23606798]\n",
      " [ 3.          2.23606798  0.        ]]\n",
      "[[ 0.          1.41421356  3.        ]\n",
      " [ 1.41421356  0.          2.23606798]\n",
      " [ 3.          2.23606798  0.        ]]\n",
      "Manhattan distance:\n",
      "[[ 0.  2.  3.]\n",
      " [ 2.  0.  3.]\n",
      " [ 3.  3.  0.]]\n",
      "[[ 0.  2.  3.]\n",
      " [ 2.  0.  3.]\n",
      " [ 3.  3.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neighbors\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# we want to calculate the pairwise distance between three points in a 2D space\n",
    "x = numpy.array([[1,3], [2, 4], [1, 6]])\n",
    "\n",
    "# Euclidean distance\n",
    "d1 = sklearn.neighbors.DistanceMetric.get_metric('euclidean')\n",
    "print(\"Euclidean distance:\")\n",
    "print(d1.pairwise(x))\n",
    "print(pairwise_distances(x, metric='euclidean'))\n",
    "# Manhattan distance\n",
    "d2 = sklearn.neighbors.DistanceMetric.get_metric('manhattan')\n",
    "print(\"Manhattan distance:\")\n",
    "print(d2.pairwise(x))\n",
    "print(pairwise_distances(x, metric='manhattan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity in scipy and scikit-learn\n",
    "\n",
    "The cosine similarity is implemented in the scipy library and in scikit-learn library.\n",
    "\n",
    "In scipy:\n",
    "`scipy.spatial.distance.cosine(x,y)` calculates the cosine distance between two points `x` and `y` where `x` and `y` are both represented by a 1-dimensional vector.\n",
    "Note that in order to convert the distance to similarity, you should subtract distance from 1.\n",
    "\n",
    "In scikit-learn:\n",
    "`sklearn.metrics.pairwise.cosine_similarity(x)` calculates the pairwise cosine similarities between all points in array `x`.\n",
    "\n",
    "\n",
    "**IMPORTANT** Verify, and remember, which of these implementations work with sparse matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity in scipy \n",
    "import scipy.spatial.distance\n",
    "x = [1, 0, -1]\n",
    "y = [-1,-1, 0]\n",
    "print(1 - scipy.spatial.distance.cosine(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-0.5  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# pairwise cosine similarity in sklearn\n",
    "import sklearn.metrics.pairwise\n",
    "x = numpy.array([[1, 0, -1], [-1,-1, 0]])\n",
    "print(sklearn.metrics.pairwise.cosine_similarity(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.4 \n",
    "\n",
    "Use the function `word_count` which you implemented in notebook [5_sparse.ipynb](5_sparse.ipynb) to create a document-term matrix from the first 100 rows of file [coco_val.txt](coco_val.txt). \n",
    "- Does your cosine function work on rows of the sparse document-term matrix? If not, do you know why not?\n",
    "- Compute the pairwise cosine similarity between the rows of your document-term matrix using the `sklearn` implementation. Which document is the most similar to the first row according to cosine similarity?  \n",
    "- Based on the above experiment, suggest ways of modifying the word counts to make the cosine similarity more useful as a metric of text similarity. Implement your idea and test it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.5\n",
    "\n",
    "Scikit learn has a couple of classes which are useful for creating various versions of document-word matrices:\n",
    "- `sklearn.feature_extraction.text.CountVectorizer`\n",
    "- `sklearn.feature_extraction.text.TfidfVectorizer`\n",
    "Read the documentation of these classes and try to apply them on the [coco_val.txt](coco_val.tx) data. \n",
    "- Compute similarities/distances using these a few versions of these document-word matrices and check how they compare to using plain word-counts as we have been doing so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
